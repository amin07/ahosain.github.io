<div class="container", style="background-color:rgb(210,200,200);">      
    <table width="95%" border="0" align="center">
      <tbody>
			<tr>
        <td width="20%"><div align="center"><img src="pp.jpg" class="dropshadow1" width="290" height="240" align="middle"></div></td>
        <td width="70%"><div align="center">
          <table width="94%" border="0">
            <tbody>
						<tr>
            <td width="19%" valign="top" height="65"></td>
            <td width="81%" valign="top">
              <h1>Al Amin Hosain</h1><table width="79%" border="0" align="left">
                <tbody><tr>
                  
                </tr>
              </tbody></table></td>          
            </tr><tr>
            <td width="19%" valign="top" height="50">Address:</td>
            <td width="81%" valign="top">George Mason University<br>
              Room: ENGR 4416, Data Mining Lab<br>
              4400 University Drive MSN 4A5
							Fairfax, VA 22030 USA
						</td></tr>
          <tr>
            <td height="22">Email:</td>
            <td>ahosain AT gmu DOT edu</td>
          </tr>
          </tbody>
					</table>
        </div>
				</td>
      </tr>
	  </tbody></table>
<hr>


I am a PhD candidate in Computer Science at <a href="http://www.gmu.edu/", style="text-decoration:none">George Mason University</a>. I am working under the supervision of Prof. <a href="https://cs.gmu.edu/~kosecka/", style="text-decoration:none">Jana Kosecka</a> and Prof. <a href="https://cs.gmu.edu/~hrangwal/", style="text-decoration:none">Huzefa Rangwala</a>. 
My research focus is application of deep learning based methods in video understanding. More specifically, I work towards applying machine learning techniques for spatial and temporal modeling of video data. 
For past couple of years, I have been extensively working on Sign Language Analysis from videos. This includes building large scale datasets and developing machine learning models for American Sign Language (ASL). 
<!--I am a senior research scientist at <a href="”https://news.developer.nvidia.com/nvidia-opens-robotics-research-lab-in-seattle/”">NVIDIA Seattle Robotics Lab</a>. I am interested in using computer vision and 3D vision for robotics tasks such as object manipulation. At the moment, I am mainly working on model-free object manipulation in unconstrained environments. In addition, I am interested in 6D pose estimation of objects, instance segmentation, and recognition from RGB-D images. Prior to NVIDIA, I finished my PhD in <a href="https://cs.gmu.edu/">Computer Science</a>
 department at <a href="http://www.gmu.edu/">George Mason University</a>
 where I was working under the supervision of Prof. <a href="https://cs.gmu.edu/~kosecka/">Jana Kosecka</a>. During my PhD, I worked on a variety of computer vision problems for robot perception such as: vision based navigation, object pose estimation, object detection, semantic segmentation and image based localization. I was fortunate to work with amazing collaborators in different research groups in industry. I did internships at Google Brain Robotics, Zoox, and Google StreetView during my PhD. Prior to my PhD, I got my masters in AI and Robotics from University of Tehran.
-->

 
<br></p>
<p class="textsectionheader1", style="font-size:20">Recent News:</p>
<hr>
<p>
</p><ul type="SQUARE">
<li> November 2020: Paper on hand pose guided pooling from 3D CNN is accepted at IEEE Winter Conference on Applications of Computer Vision (<a href="http://wacv2021.thecvf.com/">WACV2021</a>).
</li><li> August 2020: Advanced to PhD candidacy. :)
</li><li> July 2020: Passed PhD Comprehensive Exam. :)
</li><li> March 2020: Paper on hand shapes learning is accepted at 15th IEEE International Conference on Automatic Face & Gesture Recognition (<a href="https://fg2020.org/">FG2020</a>).
</li><li> August 2020: Paper on deep hand-shape feature based sign language recognition is accepted at 7th IEEE International Conference on Data Science and Advanced Analytics (<a href="http://dsaa2020.dsaa.co/">DSAA2020</a>).
</li><li> October 2019: Won the best research paper award at IEEE DSAA2019 <a href="https://dsaa.co/?p=1779">Award link</a>.
</li><li> July 2019: Paper on multi-modal sign language recognition is accepted at 6th IEEE International Conference on Data Science and Advanced Analytics (<a href="http://dsaa2019.dsaa.co/">DSAA2019</a>).
<!--</li><li> February 2020: Our paper on zero-shot pose estimation is accepted to CVPR 2020.
</li><li> January 2020: 2 papers accepted to ICRA 2020.
</li><li> October 2019: got promoted to Senior Robotics Research Scientist.
</li><li> September 2019: Our paper on evaluating different grasp sampling schemes is accepted to ISRR 2019.
</li><li> September 2019: Our paper on instance segmentation for unknown object got accepted to CoRL 2019.
</li><li> July 2019: Our paper on 6-DOF grasping of unknown objects got accepted to ICCV 2019.
</li><li> May 2019: Our paper got accepted to RSS 2019.
</li><li> January 2019: Our paper got accepted to ICRA 2019.
</li><li> August 2018: Joined NVIDIA Robotics lab as Research Scientist.
</li><li> June 2018: I defended my dissertation and graduated from PhD program.
</li><li> May 2018: Received outstanding graduate student award in CS department.
</li><li> I will be joining Google Brain team as visiting researcher for academic year of 2017.
</li><li> April 2017: Our paper got accepted to <a href="http://www.roboticsconference.org/">RSS 2017</a> conference.
</li><li> February 2017: Our <a href="https://arxiv.org/pdf/1612.00496v2.pdf">paper</a> is covered by <a href="http://spectrum.ieee.org/cars-that-think/transportation/self-driving/the-selfdriving-cars-bicycle-problem">IEEE Spectrum</a> and <a href="https://www.forbes.com/sites/kevinmurnane/2017/02/13/cyclists-may-benefit-the-most-and-be-the-greatest-challenge-for-self-driving-cars/#855847866919">Forbes</a>.
</li><li> February 2017: Our paper got accepted to <a href="http://cvpr2017.thecvf.com/">CVPR 2017</a> conference.
</li><li> September 2016: Two papers got accepted in <a href="http://3dv.stanford.edu/">3DV 2016</a> conference.
</li><li> March 2016: Second place in Computer Science PhD Symposium of George Mason University.
-->
</li></ul>
<p></p>


<p class="textsectionheader2", style="font-size:20">Publications:</p><hr>
<table width="100%" border="0">
  <tbody>
  <tr>
  <td width="60%"><p class="papertext"><strong>
Hand Pose Guided 3D Pooling for Word-level Sign Language Recognition
</strong><br>
      <strong>Al Amin Hosain</strong>, Panneer Selvam Santhalingam, Parth Pathak, Huzefa Rangwala and Jana Kosecka<br>
          IEEE Winter Conference on Applications of Computer Vision (WACV), 2021, Waikoloa, Hawaii, USA (Virtual)<br>
            <a href="">[Paper]</a> <a href="">[Video]</a>

</tbody></table>
<tbody>
  <tr>
  <td width="60%"><p class="papertext"><strong>
FineHand: Learning Hand Shapes for American Sign Language Recognition. 
</strong><br>
      <strong>Al Amin Hosain</strong>, Panneer Selvam Santhalingam, Parth Pathak, Huzefa Rangwala and Jana Kosecka<br>
          15th IEEE Conference of Face and Gesture Recognition (FaGEW Workshop), 2020, Buenos Aires, Argentina (Virtual)<br>
            <a href="https://www.computer.org/csdl/proceedings-article/fg/2020/307900a397/1kecIh5NpVC">[Paper]</a> <a href="">[Video]</a>
</tbody></table>

<tbody>
  <tr>
  <td width="60%"><p class="papertext"><strong>
Body Pose and Deep Hand-shape Feature Based American Sign Language Recognition.
</strong><br>
      <strong>Al Amin Hosain</strong>, Panneer Selvam Santhalingam, Parth Pathak, Jana Kosecka and Huzefa Rangwala<br>
          7th IEEE International Conference on Data Science and Advanced Analytics (DSAA), 2020, Sydney, Australia (Virtual)<br>
            <a href="">[Paper]</a> <a href="">[Video]</a>
</tbody></table>

<tbody>
  <tr>
  <td width="60%"><p class="papertext"><strong>
Sign Language Recognition Analysis using Multimodal Data. 
</strong><br>
      <strong>Al Amin Hosain</strong>, Panneer Selvam Santhalingam, Parth Pathak, Jana Kosecka and Huzefa Rangwala<br>
          6th IEEE International Conference on Data Science and Advanced Analytics (DSAA), 2019, Washington D.C, USA<br>
            <a href="https://arxiv.org/abs/1909.11232">[Paper]</a> <a href="">[Video]</a>
</tbody></table>

<!--
<p class="textsectionheader2">Publications:</p><hr>
<table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="imgs/biotac_intro.png" class="papericon" width="300" height="200"></td>
  <td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>
Interpreting and Predicting Tactile Signals via a Physics-Based and Data-Driven Framework
</strong><br>
      Yashraj Narang, Karl Van Wyk, <strong>Arsalan Mousavian</strong>, Dieter Fox<br>
         Robotics: Science and Systems Conference (<strong>RSS</strong>), Corvalis OR, 2020<br>
            <a href="https://arxiv.org/pdf/2006.03777.pdf">[Paper]</a> <a href="https://youtu.be/wLA-WKaeyN4">[Video]</a> <a href="https://sites.google.com/nvidia.com/tactiledata

">[Project Page]</a> <a href="bibtex/biotac_rss2020.txt">[bibtex]</a></p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>



</tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="imgs/latent_CVPR2020.png" class="papericon" width="300" height="200"></td>
  <td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>
LatentFusion: End-to-End Differentiable Reconstruction and Rendering for Unseen Object Pose Estimation
</strong><br>
      Keunhong Park, <strong>Arsalan Mousavian</strong>, Yu Xiang, Dieter Fox<br>
         IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), Seattle WA, 2020<br>
            <a href="https://arxiv.org/abs/1912.00416">[Paper]</a>  <a href="https://youtu.be/T6qSMYmlCj4">[Video]</a> <a href="bibtex/latent_fusion.txt">[bibtex]</a></p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>

</tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="gifs/icra2020.gif" class="papericon" width="300" height="130"></td>
  <td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>
6-DOF Grasping for Target-driven Object Manipulation in Clutter
</strong><br>
      Adithya Murali, <strong>Arsalan Mousavian</strong>, Clemens Eppner, Dieter Fox<br>
        International Conference on Robotics and Automation (<strong>ICRA</strong>), Paris, France, 2020<br>
        </p><p style="color:red">Best Robot Manipulation Paper Finalist<br>
        Best Student Paper Finalist</p>
            <a href="https://arxiv.org/abs/1912.03628">[Paper]</a>  <a href="https://www.youtube.com/watch?v=w0B5S-gCsJk">[Video]</a> <a href="bibtex/Clutter_GraspNet.txt">[bibtex]</a> <a href="https://blogs.nvidia.com/blog/2020/05/29/dieter-fox-award-icra/">[blog post]</a> <p></p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>

</tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="imgs/ICRA2020.png" class="papericon" width="300"></td>
  <td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>
Self-supervised 6D Object Pose Estimation for Robot Manipulation
</strong><br>
      Xinke Deng, Yu Xiang, <strong>Arsalan Mousavian</strong>, Clemens Eppner, Timothy Bretl, Dieter Fox<br>
        International Conference on Robotics and Automation (<strong>ICRA</strong>), Paris, France, 2020<br>
            <a href="https://arxiv.org/abs/1909.10159">[Paper]</a>  <a href="https://youtu.be/W1Y0Mmh1Gd8">[Video]</a> <a href="bibtex/ICRA2020_SelfSupervised.txt">[bibtex]</a></p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>

</tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="imgs/ISRR2019.png" class="papericon" width="300" height="130"></td>
  <td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>
A Billion Ways to Grasps - An Evaluation of Grasp Sampling Schemes on a Dense, Physics-based Grasp Data Set</strong><br>
      Clemens Eppner, <strong>Arsalan Mousavian</strong>, Dieter Fox<br>
        International Symposium on Robotics Research (<strong>ISRR</strong>), Hanoi, Vietnam, 2019<br>
            <a href="https://arxiv.org/abs/1912.05604">[Paper]</a> <a href="https://sites.google.com/view/abillionwaystograsp/">[Dataset]</a> <a href="bibtex/ISRR2019.txt">[bibtex]</a></p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>

</tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="https://cs.gmu.edu/~amousavi/imgs/table_clearing.gif" class="papericon" width="300" height="130"></td>
  <td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>
The Best of Both Modes: Separately Leveraging RGB and Depth for Unseen Object Instance Segmentation
</strong><br>
      Christopher Xie, Yu Xiang, <strong>Arsalan Mousavian</strong>, Dieter Fox<br>
        Conference on Robot Learning (<strong>CoRL</strong>), Osaka, Japan, 2019<br>
            <a href="https://arxiv.org/abs/1907.13236">[Paper]</a>  <a href="https://www.youtube.com/watch?v=aZkmeGIWZVw">[Video]</a> <a href="https://rse-lab.cs.washington.edu/projects/unseen-object-instance-segmentation/">[Projet Page]</a> <a href="bibtex/best_of_both_modes.txt">[bibtex]</a></p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
</tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="https://cs.gmu.edu/~amousavi/imgs/sanning_mug.gif" class="papericon" width="300"></td>
  <td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>6-DOF GraspNet: Variational Grasp Generation for Object Manipulation</strong><br>
      <strong>Arsalan Mousavian</strong>, Clemens Eppner, Dieter Fox<br>
        International Conference on Computer Vision (<strong>ICCV</strong>), Seoul, South Korea, 2019<br>
            <a href="https://arxiv.org/abs/1905.10520">[Paper]</a> <a href="https://www.youtube.com/watch?v=KNnDpGEE_NE">[Video]</a> <a href="bibtex/6DOF_GraspNet.txt">[bibtex]</a> <a href="https://github.com/NVlabs/6dof-graspnet">[Code + Data]</a> <a href="https://news.developer.nvidia.com/new-nvidia-research-helps-robots-improve-their-grasp/">[Blog Post]</a> </p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>

</tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="imgs/title_fig_reduced.png" class="papericon" width="300"></td>
  <td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>PoseRBPF: A Rao-Blackwellized Particle Filter for
6D Object Pose Tracking</strong><br>
      Xinke Deng, <strong>Arsalan Mousavian</strong>, Yu Xiang, Fei Xia, Tim Bretl, Dieter Fox<br>
        Robotics: Science and Systems Conference (<strong>RSS</strong>) Freiburg, Germany, 2019 <br>
            <a href="https://arxiv.org/pdf/1905.09304.pdf">[Paper]</a> <a href="https://www.youtube.com/watch?v=lE5gjzRKWuA">[Video]</a> <a href="https://techxplore.com/news/2019-06-poserbpf-particle-filter-6d-pose.html">[TechXplore Article]</a>  <a href="bibtex/poserbpf.txt">[bibtex]</a></p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>

  </tr></tbody><tbody>

</tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="https://cs.gmu.edu/~amousavi/gifs/smaller_fridge_2.gif" class="papericon" width="300"></td>
  <td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>Visual Represenatations for Semantic Target Driven Navigation</strong><br>
      <strong>Arsalan Mousavian</strong>, Alexander Toshev, Marek Fiser, Jana Kosecka, James Davidson<br>
        International Conference on Robotics and Automation (ICRA) Montreal, Canada, 2019<br>
            <a href="https://arxiv.org/abs/1805.06066">[Paper]</a> <a href="bibtex/nav.txt">[bibtex]</a></p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>

</tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="paper_imgs/synthetize.png" class="papericon" width="300"></td>
  <td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>Synthesizing Training Data for Object Detection in
Indoor Scenes</strong><br>
      Georgios Georgakis, <strong>Arsalan Mousavian</strong>, Alexander C. Berg, Jana Kosecka<br>
         Robotics: Science and Systems Conference (<strong>RSS</strong>), Cambridge MA, 2017<br> 
            <a href="https://arxiv.org/pdf/1702.07836.pdf">[Paper]</a> <a href="bibtex/synth.txt">[bibtex]</a></p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>



</tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="paper_imgs/deep3DBox.png" class="papericon" width="300"></td>
  <td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>3D Bounding Box Estimation Using Deep Learning and Geometry</strong><br>
      <strong>Arsalan Mousavian</strong>, Dragomir Anguelov, John Flynn, Jana Kosecka<br>
         IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), Honolulu HI, 2017<br> 
            <a href="https://arxiv.org/pdf/1612.00496v2.pdf">[Paper]</a> <a href="papers/3D-Deepbox-Supplementary.pdf">[Supplementary Material]</a> <a href="bibtex/deep3dbox.txt">[bibtex]</a> <a href="http://spectrum.ieee.org/cars-that-think/transportation/self-driving/the-selfdriving-cars-bicycle-problem">[IEEE Spectrum]</a><a href="https://www.forbes.com/sites/kevinmurnane/2017/02/13/cyclists-may-benefit-the-most-and-be-the-greatest-challenge-for-self-driving-cars/#855847866919">[Forbes]</a><br>Estimated 3D Boxes on the split of <a href="http://cvgl.stanford.edu/projects/3DVP/">3DVP</a>: <a href="results/Output3DBoxes.zip">[Download Link]</a></p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>

</tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="paper_imgs/overview_text.jpeg" class="papericon" width="300"></td>
  <td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>Joint Semantic Segmentation and Depth Estimation with Deep Convolutional Networks</strong><br>
      <strong>Arsalan Mousavian</strong>, Hamed Pirsiavash, Jana Kosecka<br>
          International Conference on 3DVision(<strong>3DV</strong>), Stanford CA, 2016<br>
            <a href="http://arxiv.org/pdf/1604.07480v3.pdf">[Paper]</a>  <a href="bibtex/segdepth.txt">[bibtex]</a> </p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
</tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="paper_imgs/dataset_img.png" class="papericon" width="300"></td>
  <td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>Multiview RGB-D Dataset for Object Instance Detection</strong><br>
     Georgios Georgakis, Md Alimoor Reza, <strong>Arsalan Mousavian</strong>, Phi-Hung Le, Jana Kosecka <br>
          International Conference on 3DVision(<strong>3DV</strong>), Stanford CA, 2016<br>
            <a href="http://cs.gmu.edu/~robot/multiview_gmu.pdf">[Paper]</a> <a href="http://cs.gmu.edu/~robot/gmu-kitchens.html">[Dataset Link]</a>  <a href="bibtex/kitchens.txt">[bibtex]</a></p>
    </td><td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>

</tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="paper_imgs/iccv_image1.png" class="papericon" width="300"></td>
  <td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>Semantic Image Based Geolocation Given a Map</strong><br>
      <strong>Arsalan Mousavian</strong>, Jana Kosecka<br>
         arXiv 2016 <br>
            <a href="https://arxiv.org/pdf/1609.00278v1.pdf">[Paper]</a> </p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
</tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="paper_imgs/ICCV_Overview1.png" class="papericon" width="300"></td>
	<td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>Deep Convolutional Features for Image Based Retrieval and Scene
Categorization</strong><br>
      <strong>Arsalan Mousavian</strong>, Jana Kosecka<br>
          arXiv 2015<br>
            <a href="http://arxiv.org/pdf/1509.06033v1.pdf">[Paper]</a>  <a href="bibtex/retrieval.txt">[bibtex]</a> </p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  </tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
  </tr><tr>
    <td width="30%"><img src="paper_imgs/ICRA_2015.png" class="papericon" width="300"></td>
	<td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>Semantically Guided Location Recognition for Outdoors Scenes</strong><br>
      <strong>Arsalan Mousavian</strong>, Jana Kosecka, Jyh-Ming Lien.<br>
      International Conference on Automation and Robotics (<strong>ICRA</strong>), Seattle WA, 2015<br>
            <a href="papers/MousavianKoseckaLien_ICRA2015.pdf">[Paper]</a> <a href="bibtex/icra_15.txt">[bibtex]</a> </p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  </tbody></table><table width="100%" border="0">
  <tbody>
  <tr>
    <td width="30%"><img src="paper_imgs/CVPRW_2015.png" class="papericon" width="300" height="100"></td>
	<td width="4%"> </td>
    <td width="60%"><p class="papertext"><strong>Semantically Aware Bag-of-words for Localization</strong><br>
      <strong>Arsalan Mousavian</strong>, Jana Kosecka.<br>
      Computer Vision and Pattern Recognition 2015 workshop on Semantic for Visual Reconstruction, Localization, and Mapping (<strong>CVPRW</strong>), Boston, MA, 2015<br>
            <a href="papers/MousavianKosecka_CVPRW2015.pdf">[Paper]</a>  <a href="bibtex/icra_15.txt">[bibtex]</a> </p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
</tbody></table> 
<br>
-->
</div>